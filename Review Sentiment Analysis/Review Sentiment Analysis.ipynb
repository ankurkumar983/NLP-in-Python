{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Sentiment Analysis using Python(NLTK/SKLEARN/pandas/numpy/matplotlib/seaborn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data courtesy of http://www.cs.jhu.edu/~mdredze/datasets/sentiment/index2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data\n",
    "positive_reviews = BeautifulSoup(open('electronics/positive.review').read(),'lxml')\n",
    "positive_reviews = positive_reviews.findAll('review_text')\n",
    "\n",
    "negative_reviews = BeautifulSoup(open('electronics/negative.review').read(),'lxml')\n",
    "negative_reviews = negative_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing text\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stopwords = set(w.rstrip() for w in open('stopwords.txt'))\n",
    "\n",
    "def my_tokenizer(s):\n",
    "    s = s.lower() # downcase\n",
    "    tokens = nltk.tokenize.word_tokenize(s) # split string into words (tokens)\n",
    "    tokens = [t for t in tokens if len(t) > 2] # remove short words, they're probably not useful\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # put words into base form\n",
    "    tokens = [t for t in tokens if t not in stopwords] # remove stopwords\n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(word_index_map): 11088\n"
     ]
    }
   ],
   "source": [
    "#create word to index map\n",
    "word_index_map = {}\n",
    "current_index = 0\n",
    "positive_tokenized = []\n",
    "negative_tokenized = []\n",
    "orig_reviews = []\n",
    "\n",
    "for review in positive_reviews:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    positive_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1\n",
    "\n",
    "for review in negative_reviews:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    negative_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1\n",
    "\n",
    "print(\"len(word_index_map):\", len(word_index_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create input matrics\n",
    "def tokens_to_vector(tokens, label):\n",
    "    x = np.zeros(len(word_index_map) + 1) # last element is for the label\n",
    "    for t in tokens:\n",
    "        i = word_index_map[t]\n",
    "        x[i] += 1\n",
    "    x = x / x.sum() # normalize it before setting label\n",
    "    x[-1] = label\n",
    "    return x\n",
    "\n",
    "N = len(positive_tokenized) + len(negative_tokenized)\n",
    "\n",
    "data = np.zeros((N, len(word_index_map) + 1))\n",
    "i = 0\n",
    "for tokens in positive_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 1)\n",
    "    data[i,:] = xy\n",
    "    i += 1\n",
    "\n",
    "for tokens in negative_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 0)\n",
    "    data[i,:] = xy\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training and test data\n",
    "orig_reviews, data = shuffle(orig_reviews, data)\n",
    "\n",
    "X = data[:,:-1]\n",
    "Y = data[:,-1]\n",
    "\n",
    "# last 100 rows will be test\n",
    "Xtrain = X[:-100,]\n",
    "Ytrain = Y[:-100,]\n",
    "Xtest = X[-100:,]\n",
    "Ytest = Y[-100:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.77\n",
      "Test accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this -0.5109992334184089\n",
      "unit -0.742151946098836\n",
      "bad -0.7565371225048386\n",
      "cable 0.689348721547398\n",
      "time -0.6773290237530438\n",
      "'ve 0.795374488830696\n",
      "month -0.7809503613677934\n",
      "pro 0.5139099816975801\n",
      "sound 0.9345898200785533\n",
      "lot 0.7416545573492085\n",
      "you 1.0658408211963322\n",
      "n't -2.0815694985020086\n",
      "easy 1.684462834092636\n",
      "quality 1.4632943134891379\n",
      "company -0.5255210786427638\n",
      "item -1.0529991143373667\n",
      "wa -1.6419524434130834\n",
      "perfect 1.0294701308540695\n",
      "fast 0.8534701271407522\n",
      "ha 0.7535072290568456\n",
      "price 2.608298908117422\n",
      "value 0.5006946733396478\n",
      "money -1.1566580199365881\n",
      "memory 0.8651598909608144\n",
      "picture 0.5630680221882312\n",
      "buy -0.9922594789801147\n",
      "... -0.6035680325538164\n",
      "bit 0.6821438304789723\n",
      "happy 0.555391260297876\n",
      "pretty 0.7269573657307102\n",
      "doe -1.1345663396020595\n",
      "highly 0.9059579946148338\n",
      "recommend 0.6147256994393698\n",
      "customer -0.6994712823175423\n",
      "support -0.8481823594691484\n",
      "little 0.8915102108491149\n",
      "returned -0.783499422448722\n",
      "excellent 1.3018632489417676\n",
      "love 1.2183812063511084\n",
      "useless -0.504018973310996\n",
      "week -0.777486095664445\n",
      "using 0.6328261304644601\n",
      "laptop 0.5854759898221373\n",
      "video 0.5139045125125269\n",
      "poor -0.8114281129296854\n",
      "look 0.5108847149584709\n",
      "then -1.1545775969203558\n",
      "tried -0.8156091887087921\n",
      "radio -0.560301933891134\n",
      "try -0.6594343406247893\n",
      "space 0.5604096449180735\n",
      "comfortable 0.646803829066113\n",
      "hour -0.5709696862878358\n",
      "expected 0.527016644283207\n",
      "speaker 0.8955246669873498\n",
      "warranty -0.5764937022039203\n",
      "stopped -0.5354312132226373\n",
      "junk -0.5638010529165288\n",
      "returning -0.5443128464257442\n",
      "paper 0.6256658074970721\n",
      "return -1.2311967658071543\n",
      "waste -1.0217456720427927\n",
      "refund -0.5941034488586582\n"
     ]
    }
   ],
   "source": [
    "#Visualise the weights of each word\n",
    "threshold = 0.5\n",
    "for word, index in word_index_map.items():\n",
    "    weight = model.coef_[0][index]\n",
    "    if weight > threshold or weight < -threshold:\n",
    "        print(word, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
